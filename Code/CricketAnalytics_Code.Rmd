---
title: Cricket Analytics using Variable Selection, Ridge Regression, LASSO, PCR, PLS and Random Forest.
author: "Rajeev Agrawal, Chaytanya Kumar, Catherine Anderson, Siqi Li"
date: "12/03/2022"
output:
  word_document: default
  pdf_document:
    extra_dependencies: subfig
fontsize: 12pt
geometry: margin=1in
header-includes:
- \usepackage{setspace}\doublespacing
- \usepackage{float}
fig_caption: yes
indent: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(message = FALSE, warning = FALSE, echo = F)
library(tidyverse)
library(ggthemes)
library(GGally)
library(patchwork)

options(scipen = 4)

#Auction data
auc22 <- read_csv("../data/IPL_Auction_2022_FullList.csv") %>%
  filter(Bid == "Sold") %>%
  dplyr::select(-`State Association`, -`2022 Set`, -`2021 Team`, -`Previous IPLTeam(s)`, -Bid, -`Bowling Style`, -`Batting Style`, -`2021 IPL`)

auc22 <- auc22 %>%
  rename(ReservePrice = `Reserve Price Rs Lakh`) %>%
  mutate(ReservePrice = ReservePrice*100000/72)

auc21_ <- read_csv("../data/IPLPlayerAuctionData.csv")
  
auc21_ %>%
  dplyr::select(-Team) %>%
  filter(Year != 2022) %>%
  group_by(Player) %>%
  arrange(desc(Year)) %>%
  slice(1) %>%
  ungroup() ->
  auc21

auc21 %>%
  inner_join(auc22, by = c("Player" = "Players")) ->
  auc21_22

#Performance data
runs21 <- read_csv("../data/MostRuns2021.csv") %>%
  dplyr::select(-POS, -Inns, -NO, -HS, -BF)
runs22 <- read_csv("../data/MostRuns2022.csv") %>%
  dplyr::select(-POS, -Inns, -NO, -HS, -BF)
w21 <- read_csv("../data/MostWickets2021.csv") %>%
  dplyr::select(-POS, -Inns, -BBI, -Avg, -`4w`, -`5w`, -Runs)
w22 <- read_csv("../data/MostWickets2022.csv") %>%
  dplyr::select(-POS, -Inns, -BBI, -Avg, -`4w`, -`5w`, -Runs)

runs21 %>%
  rename(Matches = Mat) %>%
  full_join(w21, by = "Player") %>%
  mutate(`50` = `50` + `100`) %>%
  mutate(`50` = if_else(is.na(`50`), 0, `50`)) %>%
  mutate(Matches = if_else(is.na(Matches), Mat, Matches)) %>%
  dplyr::select(-`100`, -Mat) ->
  rw21
runs22 %>%
  rename(Matches = Mat) %>%
  full_join(w22, by = "Player") %>%
  mutate(`50` = `50` + `100`) %>%
  mutate(`50` = if_else(is.na(`50`), 0, `50`)) %>%
  mutate(Matches = if_else(is.na(Matches), Mat, Matches)) %>%
  dplyr::select(-`100`, -Mat) %>%
  mutate(Avg = as.numeric(Avg)) ->
  rw22

rw21 %>%
  inner_join(auc21_22, by = "Player") %>%
  dplyr::select(-Specialism, -Country, -Year) %>%
  rename(Price_before2022 = Amount,
         Price2022 = `Price Paid`,
         StrikeRate = SR.x,
         StrikeRate_Bowling = SR.y,
         Overs = Ov,
         Economy = Econ,
         `C/U` = `C/U/A`) %>%
  mutate(Role = if_else(Role == "Wicket Keeper", "Batsman", Role)) %>%
  mutate(Price_before2022 = round(Price_before2022/72),
         Price2022 = round(Price2022/72)) %>%
  mutate(StrikeRate_Bowling = if_else(StrikeRate_Bowling == 0, 100, StrikeRate_Bowling)) %>%
  mutate(Runs = if_else(is.na(Runs), 0, Runs),
         Avg = if_else(is.na(Avg), 0, Avg),
         StrikeRate = if_else(is.na(StrikeRate), 0, StrikeRate),
         `4s` = if_else(is.na(`4s`), 0, `4s`),
         `6s` = if_else(is.na(`6s`), 0, `6s`),
         Overs = if_else(is.na(Overs), 0, Overs),
         Wkts = if_else(is.na(Wkts), 0, Wkts),
         Economy = if_else(is.na(Economy), 15, Economy),
         StrikeRate_Bowling = if_else(is.na(StrikeRate_Bowling), 100, StrikeRate_Bowling)) %>%
  mutate(Role = as.factor(Role),
         `Player Origin` = as.factor(`Player Origin`),
         `C/U` = as.factor(`C/U`),
         Team = as.factor(Team)) ->
  auc_rw21


rw21 %>%
  inner_join(auc22, by = c("Player" = "Players")) %>%
  rename(Price2022 = `Price Paid`,
         StrikeRate = SR.x,
         StrikeRate_Bowling = SR.y,
         Overs = Ov,
         Economy = Econ,
         `C/U` = `C/U/A`) %>%
  mutate(Role = case_when(Specialism == "WICKETKEEPER"~"Batsman",
                          Specialism == "BATSMAN"~"Batsman",
                          Specialism == "BOWLER"~"Bowler",
                          Specialism == "ALL-ROUNDER"~"All-Rounder")) %>%
  mutate(`Player Origin` = if_else(Country == "India", "Indian", "Overseas")) %>%
  mutate(Price2022 = round(Price2022/72)) %>%
  dplyr::select(-Specialism, -Country) %>%
  mutate(StrikeRate_Bowling = if_else(StrikeRate_Bowling == 0, 100, StrikeRate_Bowling)) %>%
  mutate(Runs = if_else(is.na(Runs), 0, Runs),
         Avg = if_else(is.na(Avg), 0, Avg),
         StrikeRate = if_else(is.na(StrikeRate), 0, StrikeRate),
         `4s` = if_else(is.na(`4s`), 0, `4s`),
         `6s` = if_else(is.na(`6s`), 0, `6s`),
         Overs = if_else(is.na(Overs), 0, Overs),
         Wkts = if_else(is.na(Wkts), 0, Wkts),
         Economy = if_else(is.na(Economy), 15, Economy),
         StrikeRate_Bowling = if_else(is.na(StrikeRate_Bowling), 100, StrikeRate_Bowling)) %>%
  mutate(Role = as.factor(Role),
         `Player Origin` = as.factor(`Player Origin`),
         `C/U` = as.factor(`C/U`),
         Team = as.factor(Team)) ->
  auc22_rw21


rw22 %>%
  inner_join(auc22, by = c("Player" = "Players")) %>%
  rename(Price2022 = `Price Paid`,
         StrikeRate = SR.x,
         StrikeRate_Bowling = SR.y,
         Overs = Ov,
         Economy = Econ,
         `C/U` = `C/U/A`) %>%
  mutate(Role = case_when(Specialism == "WICKETKEEPER"~"Batsman",
                          Specialism == "BATSMAN"~"Batsman",
                          Specialism == "BOWLER"~"Bowler",
                          Specialism == "ALL-ROUNDER"~"All-Rounder")) %>%
  mutate(`Player Origin` = if_else(Country == "India", "Indian", "Overseas")) %>%
  mutate(Price2022 = round(Price2022/72)) %>%
  dplyr::select(-Specialism, - Country) %>%
  mutate(StrikeRate_Bowling = if_else(StrikeRate_Bowling == 0, 100, StrikeRate_Bowling)) %>%
  mutate(Runs = if_else(is.na(Runs), 0, Runs),
         Avg = if_else(is.na(Avg), 0, Avg),
         StrikeRate = if_else(is.na(StrikeRate), 0, StrikeRate),
         `4s` = if_else(is.na(`4s`), 0, `4s`),
         `6s` = if_else(is.na(`6s`), 0, `6s`),
         Overs = if_else(is.na(Overs), 0, Overs),
         Wkts = if_else(is.na(Wkts), 0, Wkts),
         Economy = if_else(is.na(Economy), 15, Economy),
         StrikeRate_Bowling = if_else(is.na(StrikeRate_Bowling), 100, StrikeRate_Bowling)) %>%
  mutate(Role = as.factor(Role),
         `Player Origin` = as.factor(`Player Origin`),
         `C/U` = as.factor(`C/U`),
         Team = as.factor(Team)) ->
  auc_rw22
```

\pagebreak

## 1. Business Question and Case

### 1.1 Business Question

- What is the predicted average price of a cricket player in the Indian Premier League auction based on their performance parameters, their previous sold price, and their reserve price? 
- How can we use a trained model to calculate the measure for return on investment (ROI)? 

### 1.2 Business Case

The Indian Premier League has become a grand sport over the past decade. It is the second most valued sporting league in terms of per match value behind the National Football League (NFL) of the USA and gaining a net income of over 6 billion USD. For success to perpetuate through sport, bidding on the most skillful and valuable players is essential. Such attributes can be obtained by looking at key demographics: performance parameters, past selling prices, and their reserve price. That way, an estimated return on investment (ROI) can be established in accordance with these variables, and there can be an analysis on whether the players exceeded, receded, or met their expected prediction. Players and investors in this game need such statistical interventions to understand how much their performance is worth, and what their ranking is in certain drafting. Therefore, a calculation for return gives an overarching demonstration of these needs. 

\newpage
## 2.	Analytics Question

### 2.1 Outcome Variable of Interest

Our outcome variables of interest are 2022 Sale Price and Return on Investment for each IPL Team = (2023 Average Predicted Sale Price - 2022 Average Sale Price).  

### 2.2 Main Predictors

The key predictors of our model include demographic information such as age and country (Indian/Overseas). Their role (Batsman/Bowler/All-rounder) on the team is also a distinguished predictor variable to differentiate the value/worth. Lastly, the quality of the players' performance is a key predictor: number of runs scored, number of matches played, average batting rate, number of wickets taken, average bowling economy and reserve/base price of a player. Such predictors are important as they show us how much a player is worth based on different sets of characteristics, both broad and specialized.  

\newpage
## 3. Data set Description

For this study, the data sets were obtained from Kaggle [1][2][3]. These are three data sets that are diverse in their offerings. The 1st data set was extracted from publicly available 2022 auctioning web data presented at the two-day TATA Indian Premier League (IPL) in Bengaluru. Aspects on the bidding prices, as well as the favorability in players, in the content with 590 players being selected for auction and USD of 76,625,000 invested. The 2nd data set was a cohesive list of player performance records from 2008 to 2021 based on the ten teams appointed within the league where eleven different performance criteria were analyzed. For our data, we decided to narrow in on most runs and wickets in the period of 2021-2022. The 3rd data set is the Indian Premier League Player Auction Dataset from 2013 until now in INR; including, information on player name, role, amount, team, year, and player origin. 

\singlespacing

\newpage
## 4. Exploratory Data Analysis

### 4.1 Variables

The first data set is created by combining the data for player auctions in 2022 and prior to 2022 along with the performance data of batsmen and bowlers in 2021. It contains total 76 records with the following 24 variables:

* **Categorical variables**
  + *Role:* Player's main role - batsman, bowler or an all-rounder. Wicket keeper is treated as a batsman.
  + *Player Origin:* Indian or Overseas.
  + *C/U:* Capped = a player has played at least one international game. Uncapped = a player is yet to make an international debut. 
  + *Team:* Team a player played for in the 2022 season. PK = Punjab Kings, RR = Rajasthan Royals, SRH = Sunrisers Hyderabad, KKR = Kolkata Knight Riders, LSG = Lucknow Super Giants, CSK = chennai Super Kings, MI = Mumbai Indians, RCB = Royal Challengers Bangalore, DC = Delhi Capitals, GT = Gujarat Titans. This variable is not be used as a predictor.
* **Quantitative variables**
  + *Age:* Age of the player in years.
  + *Runs:* Total runs scored by a player in the 2021 season.
  + *Avg:* Average runs scored per innings by a player.
  + *StrikeRate:* Runs scored per 100 balls faced.
  + *50:* Number of times in 2021 season a player scored over 50 runs in a match.
  + *4s:* Number of boundaries hit by a player in the 2021 season.
  + *6s:* Number of 6s hit by a player in the 2021 season.
  + *Overs:* Number of 6-ball overs bowled by a player in the 2021 season.
  + *Wkts:* Number of wickets taken.
  + *Economy:* Number of runs given away per 6-ball over bowled. If a player has not bowled, the bowling economy is set at 15.
  + *StrikeRate_Bowling:* Number of runs given away for each wicket taken. Set to 100 if a player has bowled but failed to take a wicket.
  + *Price_before2022:* Price paid (in $) for a player prior to 2022 auction.
  + *Price2022:* Price paid (in $) for a player in the 2022 auction.
  + *ReservePrice:* Minimum price set (in $) for a player in the 2022 auction.
  + *Test caps:* Number of international 5-day test matches played.
  + *ODI caps:* Number of one-day international matches played.
  + *T20 caps:* Number of T20 international matches played.
  + *IPL:* Total number of IPL games played.
  + *Matches:* Number of IPL matches played in the season.
* **Other variables**
  + *Player:* Player name. Not a predictor in the model.

The second data set is formed after combining the data for player auctions in 2022 along with their 2021 performance data. The third data set is formed after combining the data for player auctions in 2022 along with their 2022 performance data. They contain a total of 90 and 130 records, respectively, with the same aforementioned variables except the *Price_before2022* variable. 

### 4.2 Descriptive Analytics

For the missing values in the data set, we needed to do imputation. For example, players who did not bowl any overs, were assigned Overs = 0, Wickets = 0, Economy = 15 and StrikeRate_Bowling = 100. Cleaning involved matching the mismatched player names before joining. Number of variables were renamed for consistency and to be informative. 

_4.2.1 Quick Summary_

```{r eda, out.height="35%", fig.align='center'}
#Get a quick summary of the data set
auc_rw21 %>%
  summary()
```

_4.2.2 Categorical Variables Distribution_

```{r}
#Player Origin
p1 <- auc_rw21 %>%
  ggplot(aes(x = `Player Origin`)) +
  geom_bar(fill = "indianred3") +
  labs(x = "Player Origin") + 
  theme_minimal(base_size=10)

#Capped/Uncapped
p2 <- auc_rw21 %>%
  ggplot(aes(x = `C/U`)) +
  geom_bar(fill = "seagreen2") + 
  labs(x = "Capped/Uncapped") + 
  theme_minimal(base_size=10)

#Role
p3 <- auc_rw21 %>% 
  ggplot(aes(x = Role)) +
  geom_bar(fill="orange2") +
  labs(x="Player Role") + 
  theme_minimal(base_size=10)

#Team 
p4 <- auc_rw21 %>%
  ggplot(aes(x = Team)) +
  geom_bar(fill="lightblue") + 
  labs(x = "Team") + 
  theme_minimal(base_size=10)

(p1 + p2 + p3 + p4) +
  plot_annotation(title = "Demographic and Baseline Characteristics Distribution")
```

_4.2.3 Continuous Variables Distribution_

```{r}
#Age
c1 <- auc_rw21 %>%
  ggplot(aes(Age)) + 
  geom_histogram(binwidth = 5, colour="white", fill="darkseagreen2", alpha=0.8) +
  geom_density(eval(bquote(aes(y=..count..*5))), colour="darkgreen", fill="darkgreen", alpha=0.3) +
  scale_x_continuous(breaks=seq(10,50,10)) +
  geom_vline(xintercept = 30, linetype="dashed") + 
  annotate("text", x=25, y=45, label="Age <30", size=3, color="dark green") + 
  annotate("text", x=35, y=45, label="Age >= 30", size=3, color="dark red") + 
  labs(x = "Player's Age") + 
  theme_bw()

#Matches
c2 <- auc_rw21 %>%
  ggplot(aes(Matches)) +
  geom_histogram(binwidth=3, colour="white", fill="mediumpurple2", alpha=0.8) +
  geom_density(eval(bquote(aes(y=..count..*3))), colour="mediumorchid1", fill="mediumorchid1", alpha=0.3) +
  labs(x = "Matches Played") + 
  theme_bw()

#Price 2022
c3 <- auc_rw21 %>%
  ggplot(aes(Price2022/1000)) +
  geom_histogram(bins=10, colour="white", fill="lightpink1", alpha=0.8) +
  geom_density(eval(bquote(aes(y=..count..*280))),colour="mistyrose2", fill="mistyrose2", alpha=0.3) +
  labs(x = "2022 Auction Price (in $1000)") +
  theme_bw()

#Reserve Price 2022
c3_ <- auc_rw21 %>%
  ggplot(aes(ReservePrice/1000)) +
  geom_histogram(bins=10, colour="white", fill="purple", alpha=0.8) +
  geom_density(eval(bquote(aes(y=..count..*55))),colour="mistyrose2", fill="red", alpha=0.3) +
  labs(x = "Reserve Price (in $1000)") +
  theme_bw()

#Runs
c4 <- auc_rw21 %>%
  ggplot(aes(Runs)) +
  geom_histogram(bins=6, colour="white", fill="lightgoldenrod", alpha=0.8) +
  geom_density(eval(bquote(aes(y=..count..*100))),colour="moccasin", fill="moccasin", alpha=0.3) +
  labs(x = "Runs Scored") + 
  theme_bw()

#Strike Rate
c5 <- auc_rw21 %>%
  ggplot(aes(StrikeRate)) + 
  geom_histogram(bins=5, colour="white", fill="lightskyblue2", alpha=0.8) +
  geom_density(eval(bquote(aes(y=..count..*50))),colour="lightsteelblue", fill="lightsteelblue", alpha=0.3) +
  labs(x = "Strike Rate (runs/100 balls)") + 
  theme_bw()

#6s
c6 <- auc_rw21 %>%
  ggplot(aes(`6s`)) +
  geom_histogram(bins=5, colour="white", fill="skyblue", alpha=0.8) +
  geom_density(eval(bquote(aes(y=..count..*4.4))), colour="moccasin", fill="moccasin", alpha=0.3) +
  labs(x = "6s hit in a season") + 
  theme_bw()

#Wickets
c7 <- auc_rw21 %>%
  ggplot(aes(Wkts)) + 
  geom_histogram(bins=7, colour="white", fill="lightsalmon", alpha=0.8) +
  geom_density(eval(bquote(aes(y=..count..*4.5))),colour="lightcoral", fill="lightcoral", alpha=0.3) +
  labs(x = "Wickets taken") + 
  theme_bw()

#Wickets
c8 <- auc_rw21 %>%
  ggplot(aes(Economy)) + 
  geom_histogram(bins=6, colour="green", fill="lightgreen", alpha=0.8) +
  geom_density(eval(bquote(aes(y=..count..*2.5))),colour="yellow", fill="lightyellow", alpha=0.3) +
  labs(x = "Economy (runs/over)") + 
  theme_bw()

(c1 + c2 + c4 + c5 + c6 + c7 + c8 + c3 + c3_) +
  plot_annotation(title = "Age, Matches, Runs, Strike Rate, 6s, Wickets, Bowler Economy \n 2022 Player Auction Price and 2022 Player Reserve Price")

# grid.arrange(c1, c2, c4, c5, c6, c7, c8, c3, ncol=2,
#              top = "Age, Matches, Runs, Strike Rate, 6s, Wickets, Bowler Economy and 2022 Player Auction Price")
```

### 4.3 Correlations

_4.3.1 Correlation Matrix_

```{r}
library(corrplot)
auc_rw21 %>%
  dplyr::select(-Player, -Team, -Role, -`Player Origin`) %>%
  mutate(Capped = if_else(`C/U` == "Capped", 1, 0)) %>%
  dplyr::select(-`C/U`) %>%
  cor() ->
  r

corrplot(r, order = "hclust", 
         tl.col = "black", method = "ellipse")
```

From the correlation matrix, we can see the bowling strike rate is highly correlated with the bowling economy, runs are highly correlated with 6s, 4s, scores over 50 and the average runs scored in each match, player's age is highly correlated with the number of Test, ODI and T20 caps, and number of IPL matches played. Number of matches played and the reserve price of a player are highly correlated with the 2022 player auction price. We also find that the number of wickets taken is negatively correlated with the bowling strike rate, which is to be expected. 

_4.3.2 Pairs Plot_

```{r}
auc_rw21 %>%
  dplyr::select(Matches, Age, Runs, StrikeRate, Wkts, Price2022, ReservePrice) %>%
  ggpairs()
```

\pagebreak
### 4.4 Data Pre-processing and Transformations

_4.4.1 Log Transformation_

Some of the continuous predictors such as runs scored or total wickets taken are right-skewed. One of the ways to make them closer to normal distribution is to take the logarithm. However, we have a sample size of 76 (50+ data points), therefore, the predictors do not have to be normally distributed. Hence, we leave the continuous predictors without any transformation.

\newpage
## 5. Modeling Methods

### 5.1 Initial Model Specification

_5.1.1 Training and Evaluating the Full Linear Regression Model_

Since, our outcome variable (Price2022) is quantitative, the preliminary model that we will use is the linear regression model. We see based on the p-values in the following summary output, not all of the features in this full model are significant. 

```{r}
model_p22 <- lm(Price2022 ~ . - Player - Team, data = auc_rw21)

summary(model_p22)
```

### 5.2 Assumption Tests

1. The observations are independent of each other.
2. There is no severe multicollinearity among the explanatory variables.
3. The residuals are normally distributed.
4. Homoscedasticity of the residuals.
5. The independent variables are linearly related to the response variable.
6. The sample size of the dataset is large enough to draw valid conclusions from the fitted linear regression model.
7. No extreme outliers.

Out of the above 7 assumptions, the 2nd assumption about multicollinearity will be tested using condition index (CI) and variance inflation factor (VIF). There is no evidence to suggest that the remaining 6 assumptions are violated.

_5.2.1 Dealing with Multi-collinearity_

Multi-collinearity is a problem because it makes it difficult to separate out the impact of individual predictors on response. We evaluate the overall multi-collinearity of the model using Condition Index (CI). If the model suffers from multi-collinearity (i.e. CI > 30), we will identify which predictors contribute the most to this collinearity condition using Variance Inflation Factor (VIF). A VIF of greater than 10 indicates the presence of severe multi-collinearity and requires remediation. 

```{r}
# Contains the cond.index() function to compute the CI;
library(klaR) 
# Contains the vif() function
library(car)
max(cond.index(model_p22, data = auc_rw21))
```

From the output, we can see that CI, which is the square root of the ratio of largest to the smallest Eigenvalue of the correlation matrix, is 57 > 30, implying severe multi-collinearity. Therefore, we use the VIF to estimate the variance inflation contribution of each predictor.

```{r}
vif(model_p22)
```

Many of the VIF values are greater than 5 (or even 10). We can do variable selection to deal with multi-collinearity. We can also use other ways to deal with multi-collinearity such as using shrinkage methods (Ridge, LASSO) or dimension reduction methods (PCR, PLS).

### 5.3 Smaller Nested Models 

_5.3.1 Using Step-wise Variable Selection_

Variables selection can be based on business knowledge. It is safe to remove variables that are not statistically significant. But it is not okay to remove significant variables, unless we have sound justification or serious dimensionality issues. 

Initially, p < 0.15, which is the default, is the criterion used for variable inclusion and removal, so as to retain marginally significant predictors as control variables.

```{r}
model_p22_small <- lm(Price2022 ~ 1, data = auc_rw21)

step_p22 <- step(model_p22_small, 
 scope = list(lower=model_p22_small, upper=model_p22),
 direction = "both", 
 test = "F")

summary(step_p22)

max(cond.index(step_p22, data = auc_rw21))
vif(step_p22)
```

The step_p22 model does not suffer from severe multi-collinearity with CI at 22.8 < 30 and all VIFs are way below 5. 

\newpage
_5.3.2 Using Best Subset Selection_

```{r}
library(leaps)

# best models per subset size:
reg_model <- regsubsets(Price2022 ~ . - Player - Team, 
                    data = auc_rw21, 
                    nvmax = ncol(auc_rw21) - 1, 
                    method = "exhaustive")

reg_summary <- summary(reg_model)

par(mfrow = c(1,3))
plot(reg_summary$bic, xlab = "Number of variables", ylab = "BIC", type = "l")
points(which.min(reg_summary$bic), reg_summary$bic[which.min(reg_summary$bic)], col = "red", cex = 1.5, pch = 20)

plot(reg_summary$adjr2, xlab = "Number of variables", ylab = "Adjusted R^2", type = "l")
points(which.max(reg_summary$adjr2), reg_summary$adjr2[which.max(reg_summary$adjr2)], col = "red", cex = 1.5, pch = 20)

plot(reg_summary$cp, xlab = "Number of variables", ylab = "Cp", type = "l")
lines(0:21, 0:21, col = "red")
```

So based on BIC, the best subset contains 6 variables, based on Cp, the best subset contains 21 variables while based on the Adjusted R^2, the best subset contains 14 variables. To avoid multi-collinearity, we choose model with 10 variables because it has a similar adjusted $R^2$. The 21 variable model is not useful because of the problem of severe multi-collinearity. Hence, we go with the 6 and 14 variables models. The coefficients for the 6 and 14 variables models are as follows:

```{r}
coef(reg_model, 6)
coef(reg_model, 10)
```

Now, we check for multi-collinearity. Both these models have CI < 30, so the problem of severe multi-collinearity is not there. Also, almost all of the predictors present in the model are significant. Therefore, we can choose one of these models as the preliminary OLS model.

```{r}
subset_model1 <- lm(Price2022 ~ Runs + Avg + Age + ReservePrice + Wkts + `4s`, data = auc_rw21)
summary(subset_model1)
max(cond.index(subset_model1, data = auc_rw21))

subset_model2 <- lm(Price2022 ~ Matches + Runs + Avg + Age + ReservePrice + Wkts + Economy + Role + `4s`, data = auc_rw21)
summary(subset_model2)
max(cond.index(subset_model2, data = auc_rw21))
```

\newpage
### 5.4 Model Candidates and Rationale

Rationale - Ours is a regression problem. Goal is prediction. So we choose models accordingly and compare their performance. 

- Linear Regression Model
- LASSO Model
- Ridge Regression Model
- Principal Components Regression Model
- Partial Least Squares Model
- Random Forest
- Boosted Trees

\newpage
_5.5.1 OLS_

Since the variable _Price_before2022_ does not appear to be significant, we can choose dataset 2 - auc22_rw21, which contains more number of records (90 vs. 76). We can then divide the dataset randomly into training and test parts.

```{r}
set.seed(123)
nrow(auc22_rw21) -> n #Number of records
Z <- sample(n, 70)

train <- auc22_rw21[Z,]
test <- auc22_rw21[-Z,]

ols_train <- lm(Price2022 ~ Matches + Runs + Avg + Wkts + ReservePrice + Economy + Role + Age + `4s`, data = auc22_rw21)

summary(ols_train)
max(cond.index(ols_train, data = auc22_rw21))
```

Validation set RMSE

```{r}
ols_predict <- predict(ols_train, newdata = test)
sqrt(mean((ols_predict - test$Price2022[-Z])^2))
```

\newpage
_5.5.2 LASSO_

```{r}
library(glmnet)

x <- model.matrix(Price2022 ~ . -Team -Player, data = auc22_rw21)[,-1]
y <- auc22_rw21$Price2022
x_train <- model.matrix(Price2022 ~ . -Team -Player, data = train)[,-1]
y_train <- train$Price2022
x_test <- model.matrix(Price2022 ~ . -Team -Player, data = test)[,-1]
y_test <- test$Price2022

train_lasso <- glmnet(x_train, y_train, alpha = 1,  #LASSO
                  )
plot(train_lasso)
```

In the plot, we can see how the coefficients shrink and some of them drop out as we move toward the left, that is, as the lambda goes up. Next we use 10-fold cross-validation to get the best lambda, that is, the lambda for which the deviance is the minimum.

```{r}
set.seed(123)
t_lasso.cv10 <- cv.glmnet(x_train, y_train, alpha = 1)
plot(t_lasso.cv10)

lasso.best.lambda <- t_lasso.cv10$lambda.min
```

Now we calculate the test RMSE associated with this lambda.

```{r}
lasso <- glmnet(x_train, y_train, alpha = 1, lambda = lasso.best.lambda)
lasso_pred <- predict(lasso, s = lasso.best.lambda, newx = x_test) # Use best lambda to predict test data
sqrt(mean((lasso_pred - y_test)^2)) # Calculate test RMSE
```

Finally, we refit our LASSO model on the full data set, using the value of lambda chosen by cross-validation, and examine the coefficient estimates and compare them to the plain linear regression coefficients.

```{r}
full_lasso <- glmnet(x, y, alpha = 1) # Fit LASSO model on full dataset
lasso.coef <- coef(full_lasso, s = lasso.best.lambda)
lasso.coef.0 <- coef(full_lasso, s = 0)

# Bind and round all coefficients
all.coefs <- round(cbind(lasso.coef, 
lasso.coef.0),
 digits = 3)
# Label the coefficients
colnames(all.coefs) <- c("Best LASSO", "0-Lambda LASSO")
# Display them
all.coefs
```

\newpage
_5.5.3 Ridge Regression_

```{r}
train_ridge <- glmnet(x_train, y_train, alpha = 0,  #Ridge
                  )
plot(train_ridge)
```

In the plot, we can see how the coefficients shrink but unlike LASSo none of them drop out as we move toward the left, that is, as the lambda goes up. Next we use 10-fold cross-validation to get the best lambda, that is, the lambda for which the deviance is the minimum.

```{r}
set.seed(123)
t_ridge.cv10 <- cv.glmnet(x_train, y_train, alpha = 0)
plot(t_ridge.cv10)

ridge.best.lambda <- t_ridge.cv10$lambda.min
```

Now we calculate the test RMSE associated with this lambda.

```{r}
ridge <- glmnet(x_train, y_train, alpha = 0, lambda = ridge.best.lambda)
ridge_pred <- predict(ridge, s = ridge.best.lambda, newx = x_test) # Use best lambda to predict test data
sqrt(mean((ridge_pred - y_test)^2)) # Calculate test RMSE
```

Finally, we refit our Ridge regression model on the full data set, using the value of lambda chosen by cross-validation, and examine the coefficient estimates and compare them to the plain linear regression coefficients.

```{r}
full_ridge <- glmnet(x, y, alpha = 0) # Fit Ridge model on full dataset
ridge.coef <- coef(full_ridge, s = ridge.best.lambda)
ridge.coef.0 <- coef(full_ridge, s = 0)

# Bind and round all coefficients
all.coefs <- round(cbind(ridge.coef, 
ridge.coef.0),
 digits = 3)
# Label the coefficients
colnames(all.coefs) <- c("Best Ridge", "0-Lambda Ridge")
# Display them
all.coefs
```

\newpage
_5.5.4 Principal Components Regression_

PCR model with M, the number of principal components chosen by cross-validation. 

```{r}
library(pls)
set.seed(123)
model_pcr <- pcr(Price2022 ~. - Player - Team, data = train, scale = T, 
                 validation = "CV")

validationplot(model_pcr)

summary(model_pcr)
```

Cross-validation selected M = 8. We next calculate the test RMSE.

```{r}
pcr_pred <- predict(model_pcr, test, ncomp = 8)
sqrt(pcr_mse <- mean((pcr_pred - test$Price2022)^2))
```

Finally, we refit our PCR model on the full data set, using the value of principal components chosen by cross-validation, and examine the coefficient estimates.

```{r}
full_pcr <- pcr(Price2022 ~. - Player - Team, ncomp = 8, data = auc22_rw21, scale = T)

coef(full_pcr, ncomp = 8)
```

\newpage
_5.5.5 Partial Least Squares Model_

PLS model with M, the number of principal components chosen by cross-validation. 

```{r}
set.seed(123)
model_pls <- plsr(Price2022 ~. - Player - Team, data = train, scale = T, 
                 validation = "CV")

validationplot(model_pls)
summary(model_pls)
```

Cross-validation selected M = 4 based on adjusted CV error. We next calculate the test RMSE.

```{r}
pls_pred <- predict(model_pls, test, ncomp = 4)
sqrt(mean((pls_pred - test$Price2022)^2))
```

Finally, we refit our PLS model on the full data set, using the value of principal components chosen by cross-validation, and examine the coefficient estimates.

```{r}
full_pls <- plsr(Price2022 ~. - Player - Team, ncomp = 4, data = auc22_rw21, scale = T)

coef(full_pls, ncomp = 4)
```

\newpage
_5.4.6 Random Forest_

p (number of predictors) = 20. We choose M (Number of variables per tree) = sqrt(p) = ~5 because it has been shown to give good performance.

```{r}
library(randomForest)
set.seed(1)

train %>%
  dplyr::select(-Player, -Team) %>%
  rename(Fifties = `50`,
         Fours = `4s`,
         Sixes = `6s`,
         Test = `Test caps`,
         ODI = `ODI caps`,
         T20 = `T20 caps`,
         C_U = `C/U`,
         PlayerOrigin = `Player Origin`) ->
  train_rf

test %>%
  dplyr::select(-Player, -Team) %>%
  rename(Fifties = `50`,
         Fours = `4s`,
         Sixes = `6s`,
         Test = `Test caps`,
         ODI = `ODI caps`,
         T20 = `T20 caps`,
         C_U = `C/U`,
         PlayerOrigin = `Player Origin`) ->
  test_rf

t_rf <- randomForest(Price2022~.,
                     type = "regression",
                     data = train_rf,
                      mtry = 5, importance = T)
#Tuning
ntrees <- which.min(t_rf$mse) #Number of trees

t_rf <- randomForest(Price2022~.,
                     type = "regression",
                     data = train_rf,
                     mtry = 5, importance = T,
                     ntree = ntrees)

Yhat = predict(t_rf, newdata=test_rf)

rmse.rf <- round(sqrt(mean((Yhat - test_rf$Price2022)^2)))

cbind("Root Mean Error Rate" = rmse.rf)

plot(t_rf)

varImpPlot(t_rf)
importance(t_rf)
```

\newpage
## 6. Analysis of Results/Performance Comparison

Based on the smallest test RMSE criterion, the PLS Model performs the best with RMSE = 339427. Therefore, we will use the PLS Model to estimate the measure of return on investment. To do this, we use the 3rd dataset containing 130 records and predict the 2023 Auction Price for a player based on their 2022 performance and reserve price (assuming it remains unchanged) and then calculate the difference from their actual 2022 Auction Price using which we will calculate the overall ROI for each team.

The return of investment for the teams in the descending order came out to be: Chennai Super Kings > Delhi Capitals > Rajasthan Royals > Royal Challengers > Mumbai Indians > Kolkata Knight Riders > Gujarat Lions > Lucknow Super Giants > Punjab Kings > Sunrisers Hyderabad. 

```{r}
# full_pls <- plsr(Price2022 ~. - Player - Team, ncomp = 4, data = auc_rw22, scale = T)

full_pls_pred <- predict(full_pls, auc_rw22, ncomp = 4)
#sqrt(mean((full_pls_pred - auc_rw22$Price2022)^2)) #RMSE

cbind(full_pls_pred, auc_rw22) %>%
  dplyr::select(`Price2022.4 comps`, Price2022, Team) %>%
  rename(Price2023 = `Price2022.4 comps`) %>%
  mutate(Price2023 = round(Price2023)) ->
  auc23_22

auc23_22 %>%
  group_by(Team) %>%
  mutate(`ROI` = round(mean(Price2023 - Price2022))) %>%
  ungroup() ->
  auc23_22

auc23_22 %>%
  mutate(Team = case_when(Team == "GT"~"Gujarat Lions",
                          Team == "KKR"~"Kolkata Knight Riders",
                          Team == "RR"~"Rajasthan Royals",
                          Team == "RCB"~"Royal Challengers Bangalore",
                          Team == "SRH"~"Sunrisers Hyderabad",
                          Team == "MI"~"Mumbai Indians",
                          Team == "DC"~"Delhi Capitals",
                          Team == "PK"~"Punjab Kings",
                          Team == "CSK"~"Chennai Super Kings",
                          Team == "LSG"~"Lucknow Super Giants")) %>%
  dplyr::select(Team, `ROI`) %>%
  unique() %>%
  arrange(desc(`ROI`)) %>%
  mutate(`ROI Rank` = row_number()) %>%
  dplyr::select(-`ROI`) ->
  roi

roi %>%
  knitr::kable()
```

\doublespacing
\pagebreak
## 7. Conclusion

The capability to calculate the return on investment early assumes a vital role for a sport team's long-term performance and decision making. Machine learning methods are valuable in this regard. In the current study, 5 machine learning classifiers (Ridge, LASSO, PCR, PLS and Random Forest) were applied on a training data set and validated against a test data set; both of these data sets were based on the publicly available 2022 auctioning web data presented at the two-day TATA Indian Premier League (IPL) in Bengaluru. The results of our model implementations show that based on the measures of future performance - the lowest test RMSE, PLS model performed the best. Originally, we sought out to find the best ROI price for each player. However, with such high RMSE, we instead decided to base the performance comparisons on team outcomes. 

One limitation of the current study is that the player's international cricket performance, which may also be a predictor of a player's 2022 Sale price, is not found in the dataset, which only includes the player's prior IPL results. Also, the players' victories in games and their performance in victories on match day were not considered. It is likely that emotional bias and popularity may be factors involved in team decision-making and them offering a certain price for a player.   

Another limitation of the present study that we report is the small size of the dataset (n = 76): a larger dataset would have permitted us to obtain more reliable results.

\pagebreak
## Appendices

### A. R Code



### B. References
\footnotesize
1. https://www.kaggle.com/datasets/vinitshah0110/ipl-auction-2022
2. https://www.kaggle.com/datasets/iamsouravbanerjee/ipl-player-performance-dataset
3. https://www.kaggle.com/datasets/kalilurrahman/ipl-player-auction-dataset-from-start-to-now
